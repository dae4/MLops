from fastapi import FastAPI, File, UploadFile
from ultralytics import YOLO
import uvicorn
import os
import glob
import cv2
import numpy as np
from io import BytesIO
from PIL import Image

app = FastAPI(title="YOLO MLOps Inference Server")

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ê´€ë¦¬
model = None

# í”„ë¡œì íŠ¸ ê²½ë¡œ (Docker ë‚´ë¶€ ê²½ë¡œ ê¸°ì¤€)
PROJECT_DIR = "/data1/project/private/MLops"
TRAIN_DIR = f"{PROJECT_DIR}/runs/train"

class ModelUpdate(BaseModel):
    model_path: str

def load_model(path: str):
    global model
    try:
        print(f"ğŸ”„ Loading model from: {path}")
        model = YOLO(path)
        print("âœ… Model loaded successfully!")
        return True
    except Exception as e:
        print(f"âŒ Failed to load model: {e}")
        return False
    
def get_latest_model():
    """
    runs/train í´ë”ì—ì„œ ê°€ì¥ ìµœê·¼ì— ìƒì„±ëœ best.pt íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤.
    """
    # exp_ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  í´ë” ê²€ìƒ‰
    search_path = f"{TRAIN_DIR}/coco_*/weights/best.pt"
    list_of_files = glob.glob(search_path)
    
    if not list_of_files:
        return None
        
    # ìƒì„± ì‹œê°„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê°€ì¥ ë§ˆì§€ë§‰ íŒŒì¼ ì„ íƒ
    latest_file = max(list_of_files, key=os.path.getctime)
    return latest_file

if initial_model_path:
    load_model(initial_model_path)

# ëª¨ë¸ ì¬ë¡œë”© ì—”ë“œí¬ì¸íŠ¸
@app.post("/reload")
def reload_model_endpoint(update: ModelUpdate):
    """
    Airflowë¡œë¶€í„° ìƒˆë¡œìš´ ëª¨ë¸ ê²½ë¡œë¥¼ ë°›ì•„ì„œ ì¦‰ì‹œ êµì²´í•©ë‹ˆë‹¤.
    """
    if not os.path.exists(update.model_path):
        raise HTTPException(status_code=400, detail="Model file not found.")
    
    success = load_model(update.model_path)
    if success:
        return {"status": "success", "message": f"Model reloaded: {update.model_path}"}
    else:
        raise HTTPException(status_code=500, detail="Failed to load model.")   
 
# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ë¡œë“œ (ì„œë²„ ì‹œì‘ ì‹œ 1íšŒ)
print("ğŸ”„ Searching for the latest model...")
model_path = get_latest_model()

if model_path:
    print(f"âœ… Model found: {model_path}")
    model = YOLO(model_path)
else:
    print("âš ï¸ No model found! Server will start but cannot predict.")
    model = None

@app.get("/")
def read_root():
    return {"status": "healthy", "model_path": model_path}

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    """
    ì´ë¯¸ì§€ë¥¼ ë°›ì•„ì„œ YOLO ì¶”ë¡  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if model is None:
        return {"error": "Model not loaded yet."}

    # 1. ì´ë¯¸ì§€ ì½ê¸°
    contents = await file.read()
    image = Image.open(BytesIO(contents))
    
    # 2. ì¶”ë¡  ì‹¤í–‰
    results = model.predict(image)
    
    # 3. ê²°ê³¼ íŒŒì‹± (JSON ë³€í™˜)
    detections = []
    for result in results:
        for box in result.boxes:
            detections.append({
                "class": int(box.cls),
                "name": model.names[int(box.cls)],
                "confidence": float(box.conf),
                "bbox": box.xyxy.tolist()[0]
            })
            
    return {"filename": file.filename, "detections": detections}

if __name__ == "__main__":
    # 8000ë²ˆ í¬íŠ¸ë¡œ ì‹¤í–‰
    uvicorn.run(app, host="0.0.0.0", port=8888)